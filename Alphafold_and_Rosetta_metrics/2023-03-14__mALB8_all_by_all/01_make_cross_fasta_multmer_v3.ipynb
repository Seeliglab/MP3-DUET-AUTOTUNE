{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aljubetic/AF2/projects/2023-03-14__mALB8_all_by_all\n",
      "headnode\n"
     ]
    }
   ],
   "source": [
    "import os; print(os.getcwd())\n",
    "import socket; print(socket.gethostname())\n",
    "import os\n",
    "from glob import glob\n",
    "from Bio import SeqIO\n",
    "import truncator as u\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = SeqIO.to_dict(SeqIO.parse(open('data/mALB8.fasta'),'fasta'))\n",
    "out_dir = pathlib.Path('out/01__multimer-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a big all-by-all fasta file\n",
    "\n",
    "\n",
    "with open('01-all-by-all.fasta', 'w') as out_file:\n",
    "    for id1 in seqs.keys():\n",
    "        for id2 in seqs.keys():\n",
    "            name = f'{id1}__{id2}'\n",
    "            # get rid of - and white space\n",
    "            seq1 = ''.join(str(seqs[id1].seq).replace('-','').split())\n",
    "            seq2 = ''.join(str(seqs[id2].seq).replace('-','').split())\n",
    "            out_file.write(f'>{name}\\n')\n",
    "            out_file.write(f'{seq1}:{seq2}\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_fasta(name, list_of_seq):\n",
    "    with open(name, 'w') as out_file:\n",
    "        for seq in list_of_seq:\n",
    "            out_file.write(f'>{seq.id}\\n')\n",
    "            out_file.write(f'{seq.seq}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the big fasta file\n",
    "seqs = SeqIO.to_dict(SeqIO.parse(open('01-all-by-all.fasta'),'fasta'))\n",
    "#Sort by length\n",
    "seqs = dict(sorted(seqs.items(), key=lambda item: len(item[1])))\n",
    "write_to_fasta('01-all-by-all.fasta', seqs.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GROUP_SIZE =7 \n",
    "MAX_GROUP_TOTAL_AA   = 3000\n",
    "MAX_SIZE_CHANGE = 1.1\n",
    "\n",
    "GROUPS = []\n",
    "\n",
    "seq_list = list(seqs.values())\n",
    "\n",
    "#add fist sequence to group\n",
    "\n",
    "seq = seq_list[0]\n",
    "group_index = 0\n",
    "GROUPS.append([seq])\n",
    "group_size = 1\n",
    "group_total_AA = len(seq) \n",
    "last_added_length = len(seq)\n",
    "\n",
    "for seq in seq_list[1:]:\n",
    "    #if change in criteria\n",
    "    size_change = len(seq)/last_added_length  \n",
    "    if group_size > MAX_GROUP_SIZE or group_total_AA > MAX_GROUP_TOTAL_AA or size_change > MAX_SIZE_CHANGE:\n",
    "        #Make a new group\n",
    "        group_index = group_index + 1\n",
    "        GROUPS.append([seq])\n",
    "        group_size = 1\n",
    "        group_total_AA = len(seq) \n",
    "        last_added_length = len(seq)\n",
    "    else:\n",
    "        GROUPS[group_index].append(seq)\n",
    "        group_size += 1\n",
    "        group_total_AA += len(seq) \n",
    "        last_added_length = len(seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.make_dirs(out_dir)\n",
    "for n, g in enumerate(GROUPS):\n",
    "    write_to_fasta(out_dir/f\"g{n:04d}.fasta\", g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/01__multimer-v3/run.tasks\n"
     ]
    }
   ],
   "source": [
    "fastas = sorted(glob(f'{out_dir}/*.fasta'))\n",
    "\n",
    "print(f'{out_dir}/run.tasks')\n",
    "with open(f'{out_dir}/run.tasks', 'w') as f:\n",
    "    for fasta in fastas:\n",
    "        fasta_name = u.basename_noext(fasta)\n",
    "        f.write(f'source /home/aljubetic/bin/set_up_AF2.3.sh && mkdir -p {out_dir/fasta_name} && '\n",
    "        f'/home/aljubetic/AF2/CF2.3/colabfold-conda/bin/colabfold_batch  --msa-mode single_sequence  --amber --model-type alphafold2_multimer_v3 {fasta} {out_dir/fasta_name} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source /home/aljubetic/bin/set_up_AF2.3.sh && mkdir -p out/01__multimer-v3/g0000 && /home/aljubetic/AF2/CF2.3/colabfold-conda/bin/colabfold_batch  --msa-mode single_sequence  --amber --model-type alphafold2_multimer_v3 out/01__multimer-v3/g0000.fasta out/01__multimer-v3/g0000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmds = u.read_file_lines(f'{out_dir}/run.tasks', trim=True)\n",
    "cmds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch  --partition=gpu --gres=gpu:A40:1 --ntasks=1 --cpus-per-task=2 --job-name=mALB8-all-by-all --output=mALB8-all-by-all.out -e mALB8-all-by-all.err  --wrap=\"source /home/aljubetic/bin/set_up_AF2.3.sh && mkdir -p out/01__multimer-v3/g0000 && /home/aljubetic/AF2/CF2.3/colabfold-conda/bin/colabfold_batch  --msa-mode single_sequence  --amber --model-type alphafold2_multimer_v3 out/01__multimer-v3/g0000.fasta out/01__multimer-v3/g0000\" \n"
     ]
    }
   ],
   "source": [
    "###TEST one\n",
    "job_name='mALB8-all-by-all'\n",
    "# -N 1 --nodelist=compute-3-[18,21],compute-6-0,compute-3-[19-20],compute-6-[1-4]\n",
    "slurm_params = f'--partition=gpu --gres=gpu:A40:1 --ntasks=1 --cpus-per-task=2 --job-name={job_name} --output={job_name}.out -e {job_name}.err '\n",
    "\n",
    "print(f\"\"\"sbatch  {slurm_params} --wrap=\"{cmds[0]}\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 41111\n"
     ]
    }
   ],
   "source": [
    "GROUP_SIZE=1\n",
    "task_list=f'{out_dir}/run.tasks'\n",
    "from math import ceil; num_tasks = ceil(len(cmds)/GROUP_SIZE)\n",
    "!export GROUP_SIZE={GROUP_SIZE}; sbatch {slurm_params} -a 1-{num_tasks} /home/aljubetic/scripts/wrapper_slurm_array_job_group.sh {task_list} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "     41111_[58-61]       gpu mALB8-al aljubeti PD       0:00      1 (Resources)\n",
      "           41111_1       gpu mALB8-al aljubeti  R       0:03      1 compute-0-11\n",
      "           41111_2       gpu mALB8-al aljubeti  R       0:03      1 compute-0-11\n",
      "           41111_3       gpu mALB8-al aljubeti  R       0:03      1 compute-0-11\n",
      "           41111_4       gpu mALB8-al aljubeti  R       0:03      1 compute-0-11\n",
      "           41111_5       gpu mALB8-al aljubeti  R       0:03      1 compute-0-11\n",
      "           41111_6       gpu mALB8-al aljubeti  R       0:03      1 compute-0-10\n",
      "           41111_7       gpu mALB8-al aljubeti  R       0:03      1 compute-0-10\n",
      "           41111_8       gpu mALB8-al aljubeti  R       0:03      1 compute-0-10\n",
      "           41111_9       gpu mALB8-al aljubeti  R       0:03      1 compute-0-10\n",
      "          41111_10       gpu mALB8-al aljubeti  R       0:03      1 compute-0-10\n",
      "          41111_11       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_12       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_13       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_14       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_15       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_16       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_17       gpu mALB8-al aljubeti  R       0:03      1 compute-0-12\n",
      "          41111_18       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_19       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_20       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_21       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_22       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_23       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_24       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_25       gpu mALB8-al aljubeti  R       0:03      1 compute-6-1\n",
      "          41111_26       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_27       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_28       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_29       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_30       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_31       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_32       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_33       gpu mALB8-al aljubeti  R       0:03      1 compute-6-0\n",
      "          41111_34       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_35       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_36       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_37       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_38       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_39       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_40       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_41       gpu mALB8-al aljubeti  R       0:03      1 compute-6-2\n",
      "          41111_42       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_43       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_44       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_45       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_46       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_47       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_48       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_49       gpu mALB8-al aljubeti  R       0:03      1 compute-6-3\n",
      "          41111_50       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_51       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_52       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_53       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_54       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_55       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_56       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n",
      "          41111_57       gpu mALB8-al aljubeti  R       0:03      1 compute-6-4\n"
     ]
    }
   ],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 24290331 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0061bb4dbc2b17a5a419ea32aa745a1e58e3f554c70fb15d38989b4499d4f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
